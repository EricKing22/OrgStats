{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 测试\n",
    "## 使用复旦大学项目测试api"
   ],
   "id": "41bd0b9aaabbd8b9"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-06T16:23:43.058802Z",
     "start_time": "2025-09-06T16:23:42.662685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from click import prompt\n",
    "\n",
    "org = \"OpenMOSS\"\n",
    "\n",
    "url = f\"https://api.github.com/orgs/{org}/repos?per_page=100\"\n",
    "headers = {\"Accept\": \"application/vnd.github+json\"}  # 可加 Authorization 提高速率限制\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "repos = response.json()\n",
    "\n",
    "context = []\n",
    "\n",
    "for repo in repos:\n",
    "    if int(repo[\"stargazers_count\"]) >= 50:\n",
    "        context.append({\n",
    "            \"name\": repo[\"name\"],\n",
    "            \"description\": repo.get(\"description\"),\n",
    "            \"created_at\": repo.get(\"created_at\"),\n",
    "            \"updated_at\": repo.get(\"updated_at\"),\n",
    "            \"stars\": repo.get(\"stargazers_count\",0),\n",
    "            \"url\": repo.get(\"html_url\")\n",
    "        })\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T16:23:43.073974Z",
     "start_time": "2025-09-06T16:23:43.065803Z"
    }
   },
   "cell_type": "code",
   "source": "context",
   "id": "89458db7f775001e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'CoLLiE',\n",
       "  'description': 'Collaborative Training of Large Language Models in an Efficient Way',\n",
       "  'created_at': '2023-04-02T11:10:19Z',\n",
       "  'updated_at': '2025-08-20T07:08:09Z',\n",
       "  'stars': 416,\n",
       "  'url': 'https://github.com/OpenMOSS/CoLLiE'},\n",
       " {'name': 'MOSS',\n",
       "  'description': 'An open-source tool-augmented conversational language model from Fudan University',\n",
       "  'created_at': '2023-04-15T14:07:44Z',\n",
       "  'updated_at': '2025-09-06T03:26:11Z',\n",
       "  'stars': 12060,\n",
       "  'url': 'https://github.com/OpenMOSS/MOSS'},\n",
       " {'name': 'HalluQA',\n",
       "  'description': 'Dataset and evaluation script for \"Evaluating Hallucinations in Chinese Large Language Models\"',\n",
       "  'created_at': '2023-10-04T03:01:40Z',\n",
       "  'updated_at': '2025-08-07T12:29:33Z',\n",
       "  'stars': 132,\n",
       "  'url': 'https://github.com/OpenMOSS/HalluQA'},\n",
       " {'name': 'Say-I-Dont-Know',\n",
       "  'description': \"[ICML'2024] Can AI Assistants Know What They Don't Know?\",\n",
       "  'created_at': '2024-01-18T03:18:26Z',\n",
       "  'updated_at': '2025-08-14T01:24:31Z',\n",
       "  'stars': 83,\n",
       "  'url': 'https://github.com/OpenMOSS/Say-I-Dont-Know'},\n",
       " {'name': 'AnyGPT',\n",
       "  'description': 'Code for \"AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling\"',\n",
       "  'created_at': '2024-02-18T08:09:11Z',\n",
       "  'updated_at': '2025-09-05T09:52:30Z',\n",
       "  'stars': 861,\n",
       "  'url': 'https://github.com/OpenMOSS/AnyGPT'},\n",
       " {'name': 'GAOKAO-MM',\n",
       "  'description': \"[ACL'2024 Findings] GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models Evaluation\",\n",
       "  'created_at': '2024-02-21T07:40:36Z',\n",
       "  'updated_at': '2025-08-07T08:05:22Z',\n",
       "  'stars': 65,\n",
       "  'url': 'https://github.com/OpenMOSS/GAOKAO-MM'},\n",
       " {'name': 'Language-Model-SAEs',\n",
       "  'description': \"For OpenMOSS Mechanistic Interpretability Team's Sparse Autoencoder (SAE) research.\",\n",
       "  'created_at': '2024-03-19T04:04:31Z',\n",
       "  'updated_at': '2025-08-30T07:41:14Z',\n",
       "  'stars': 146,\n",
       "  'url': 'https://github.com/OpenMOSS/Language-Model-SAEs'},\n",
       " {'name': 'VLABench',\n",
       "  'description': 'Official repo of VLABench, a large scale benchmark designed for fairly evaluating VLA, Embodied Agent, and VLMs.',\n",
       "  'created_at': '2024-12-25T10:51:07Z',\n",
       "  'updated_at': '2025-09-04T07:55:24Z',\n",
       "  'stars': 283,\n",
       "  'url': 'https://github.com/OpenMOSS/VLABench'},\n",
       " {'name': 'SpeechGPT-2.0-preview',\n",
       "  'description': 'GPT-4o-level, real-time spoken dialogue system.',\n",
       "  'created_at': '2025-01-26T10:08:36Z',\n",
       "  'updated_at': '2025-09-02T16:15:32Z',\n",
       "  'stars': 354,\n",
       "  'url': 'https://github.com/OpenMOSS/SpeechGPT-2.0-preview'},\n",
       " {'name': 'Thus-Spake-Long-Context-LLM',\n",
       "  'description': 'a survey of long-context LLMs from four perspectives, architecture, infrastructure, training, and evaluation',\n",
       "  'created_at': '2025-01-28T04:27:06Z',\n",
       "  'updated_at': '2025-08-20T14:06:22Z',\n",
       "  'stars': 56,\n",
       "  'url': 'https://github.com/OpenMOSS/Thus-Spake-Long-Context-LLM'},\n",
       " {'name': 'MOSS-TTSD',\n",
       "  'description': 'MOSS-TTSD is a spoken dialogue generation model that enables expressive dialogue speech synthesis in both Chinese and English, supporting zero-shot multi-speaker voice cloning, and long-form speech generation.',\n",
       "  'created_at': '2025-06-17T06:32:14Z',\n",
       "  'updated_at': '2025-09-05T09:33:43Z',\n",
       "  'stars': 941,\n",
       "  'url': 'https://github.com/OpenMOSS/MOSS-TTSD'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T16:23:44.089593Z",
     "start_time": "2025-09-06T16:23:43.246559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:8890\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:8890\"\n",
    "# ucloud api key\n",
    "API_KEY = os.getenv(\"UCLOUD_API_KEY\")\n",
    "API_BASE = \"https://api.modelverse.cn/v1\"\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base=API_BASE,\n",
    "    model=\"deepseek-ai/DeepSeek-V3-0324\")\n",
    "output_parser = StrOutputParser()\n"
   ],
   "id": "2e0ba11fabff141e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T16:23:59.841058Z",
     "start_time": "2025-09-06T16:23:44.107108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=\"\"\"\n",
    "\n",
    "请根据json格式数据中description的内容分类到这些标签，最后更新时间（updated_at)2023年之前的项目请省略，如果输入jason格式为空请跳过一下内容，直接输出“此组织在GitHub上无star数大于50的项目”：\n",
    "\n",
    "模型（如大语言模型，多模态模型等）\n",
    "数据集（各类database或者dataset）\n",
    "工具（各种可用于辅助的ai工具）\n",
    "其他\n",
    "\n",
    "jason数据为：\n",
    "\n",
    "{context}\n",
    "\n",
    "请逐个输出每个项目的分类，并以star数量排序（最多star数量的在最前面），\n",
    "\n",
    "\n",
    "输出格式按照：\n",
    "\n",
    "**项目名**\n",
    "分类：\n",
    "star数字：\n",
    "最后更新时间：\n",
    "项目描述：(用你自己的话总结一下）\n",
    "url:\n",
    "\n",
    "在输出前确认一下格式以及是否有按star数排序\n",
    "\"\"\")\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "result = chain.invoke({\"context\":context})\n",
    "print(result)"
   ],
   "id": "4f215e187d5dfb9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是按照star数量排序后的项目分类结果，仅包含star数大于50且最后更新时间在2023年及之后的项目：\n",
      "\n",
      "---\n",
      "\n",
      "**MOSS**  \n",
      "分类：模型  \n",
      "star数字：12060  \n",
      "最后更新时间：2025-09-06  \n",
      "项目描述：复旦大学开源的增强工具对话语言模型。  \n",
      "url: https://github.com/OpenMOSS/MOSS  \n",
      "\n",
      "---\n",
      "\n",
      "**MOSS-TTSD**  \n",
      "分类：模型  \n",
      "star数字：941  \n",
      "最后更新时间：2025-09-05  \n",
      "项目描述：支持中英文表达性对话语音合成的模型，具备零样本多说话人克隆和长文本生成能力。  \n",
      "url: https://github.com/OpenMOSS/MOSS-TTSD  \n",
      "\n",
      "---\n",
      "\n",
      "**AnyGPT**  \n",
      "分类：模型  \n",
      "star数字：861  \n",
      "最后更新时间：2025-09-05  \n",
      "项目描述：基于离散序列建模的统一多模态大语言模型。  \n",
      "url: https://github.com/OpenMOSS/AnyGPT  \n",
      "\n",
      "---\n",
      "\n",
      "**CoLLiE**  \n",
      "分类：工具  \n",
      "star数字：416  \n",
      "最后更新时间：2025-08-20  \n",
      "项目描述：高效协作训练大语言模型的方法。  \n",
      "url: https://github.com/OpenMOSS/CoLLiE  \n",
      "\n",
      "---\n",
      "\n",
      "**SpeechGPT-2.0-preview**  \n",
      "分类：模型  \n",
      "star数字：354  \n",
      "最后更新时间：2025-09-02  \n",
      "项目描述：达到GPT-4o水平的实时口语对话系统。  \n",
      "url: https://github.com/OpenMOSS/SpeechGPT-2.0-preview  \n",
      "\n",
      "---\n",
      "\n",
      "**VLABench**  \n",
      "分类：数据集  \n",
      "star数字：283  \n",
      "最后更新时间：2025-09-04  \n",
      "项目描述：用于公平评估视觉语言代理（VLA）、具身智能体和多模态模型的大规模基准。  \n",
      "url: https://github.com/OpenMOSS/VLABench  \n",
      "\n",
      "---\n",
      "\n",
      "**Language-Model-SAEs**  \n",
      "分类：工具  \n",
      "star数字：146  \n",
      "最后更新时间：2025-08-30  \n",
      "项目描述：专注于稀疏自编码器（SAE）在语言模型可解释性中的研究工具。  \n",
      "url: https://github.com/OpenMOSS/Language-Model-SAEs  \n",
      "\n",
      "---\n",
      "\n",
      "**HalluQA**  \n",
      "分类：数据集  \n",
      "star数字：132  \n",
      "最后更新时间：2025-08-07  \n",
      "项目描述：用于评估中文大语言模型幻觉现象的数据集和脚本。  \n",
      "url: https://github.com/OpenMOSS/HalluQA  \n",
      "\n",
      "---\n",
      "\n",
      "**Say-I-Dont-Know**  \n",
      "分类：其他  \n",
      "star数字：83  \n",
      "最后更新时间：2025-08-14  \n",
      "项目描述：研究AI助手能否识别自身知识盲区的项目（ICML 2024）。  \n",
      "url: https://github.com/OpenMOSS/Say-I-Dont-Know  \n",
      "\n",
      "---\n",
      "\n",
      "**GAOKAO-MM**  \n",
      "分类：数据集  \n",
      "star数字：65  \n",
      "最后更新时间：2025-08-07  \n",
      "项目描述：中文多模态模型评估基准（ACL 2024 Findings）。  \n",
      "url: https://github.com/OpenMOSS/GAOKAO-MM  \n",
      "\n",
      "---\n",
      "\n",
      "**Thus-Spake-Long-Context-LLM**  \n",
      "分类：其他  \n",
      "star数字：56  \n",
      "最后更新时间：2025-08-20  \n",
      "项目描述：从架构、基础设施、训练和评估四个角度分析长上下文大语言模型的综述。  \n",
      "url: https://github.com/OpenMOSS/Thus-Spake-Long-Context-LLM  \n",
      "\n",
      "--- \n",
      "\n",
      "所有项目已按star数降序排列，并确保格式统一。\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T16:24:05.231781Z",
     "start_time": "2025-09-06T16:24:05.213740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(f\"Github/{org}_results.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(result)"
   ],
   "id": "42fea8d2feedbdfe",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 生产\n",
    "## 从Github上搜索信息"
   ],
   "id": "57edb41a03aa003a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T07:34:43.892692Z",
     "start_time": "2025-09-06T07:34:43.878302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "github_orgs = \"\"\"\n",
    "FudanDISC\n",
    "OpenMOSS\n",
    "fudan-generative-vision\n",
    "Thinklab-SJTU\n",
    "VISION-SJTU\n",
    "USTCAGI\n",
    "ECNU-CILAB\n",
    "opengvlab\n",
    "stepfun-ai\n",
    "minimax-ai\n",
    "OpenSenseNova\n",
    "loongOpen\n",
    "AgibotTech\n",
    "FFTAI\n",
    "4paradigm\n",
    "TigerResearch\n",
    "infly-ai\n",
    "IAAR-Shanghai\n",
    "MemTensor\n",
    "infinigence\n",
    "\"\"\""
   ],
   "id": "ffb74e8eb2a8ce72",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T07:29:02.981766Z",
     "start_time": "2025-09-06T07:23:29.772473Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [05:33<00:00, 19.60s/it]\n"
     ]
    }
   ],
   "execution_count": 45,
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "webs = github_orgs.strip().split(\"\\n\")\n",
    "\n",
    "for org in tqdm(webs, total=len(webs)):\n",
    "    url = f\"https://api.github.com/orgs/{org}/repos?per_page=100\"\n",
    "    headers = {\"Accept\": \"application/vnd.github+json\"}  # 可加 Authorization 提高速率限制\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    repos = response.json()\n",
    "\n",
    "    context = []\n",
    "\n",
    "    for repo in repos:\n",
    "        try:\n",
    "            if int(repo[\"stargazers_count\"]) >= 50:\n",
    "                context.append({\n",
    "                    \"name\": repo[\"name\"],\n",
    "                    \"description\": repo[\"description\"],\n",
    "                    \"created_at\": repo[\"created_at\"],\n",
    "                    \"updated_at\": repo[\"updated_at\"],\n",
    "                    \"stars\": repo[\"stargazers_count\"],\n",
    "                    \"url\": repo[\"html_url\"]\n",
    "                })\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    result = chain.invoke({\"context\":context})\n",
    "    with open(f\"Github/{org}_results.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(result)"
   ],
   "id": "8cf9ab2848f24e79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T07:21:04.257509Z",
     "start_time": "2025-09-06T07:21:02.614748Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'R3Det_Tensorflow',\n",
       "  'description': 'Code for AAAI 2021 paper: R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object',\n",
       "  'created_at': '2019-08-27T14:42:38Z',\n",
       "  'updated_at': '2025-03-06T05:52:31Z',\n",
       "  'stars': 546,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/R3Det_Tensorflow'},\n",
       " {'name': 'ThinkMatch',\n",
       "  'description': 'A research protocol for deep graph matching.',\n",
       "  'created_at': '2019-09-06T17:07:08Z',\n",
       "  'updated_at': '2025-08-31T14:47:22Z',\n",
       "  'stars': 872,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/ThinkMatch'},\n",
       " {'name': 'CSL_RetinaNet_Tensorflow',\n",
       "  'description': 'Code for ECCV 2020 paper: Arbitrary-Oriented Object Detection with Circular Smooth Label',\n",
       "  'created_at': '2020-03-07T08:48:15Z',\n",
       "  'updated_at': '2025-06-13T20:11:34Z',\n",
       "  'stars': 192,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow'},\n",
       " {'name': 'S2TLD',\n",
       "  'description': 'Newly released traffic light dataset for small object detection.',\n",
       "  'created_at': '2020-04-28T03:01:40Z',\n",
       "  'updated_at': '2025-05-13T02:06:16Z',\n",
       "  'stars': 59,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/S2TLD'},\n",
       " {'name': 'awesome-ml4co',\n",
       "  'description': 'Awesome machine learning for combinatorial optimization papers.',\n",
       "  'created_at': '2021-03-21T09:07:51Z',\n",
       "  'updated_at': '2025-09-02T02:34:31Z',\n",
       "  'stars': 1950,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/awesome-ml4co'},\n",
       " {'name': 'PPO-BiHyb',\n",
       "  'description': 'Implementation of our NeurIPS 2021 paper \"A Bi-Level Framework for Learning to Solve Combinatorial Optimization on Graphs\".',\n",
       "  'created_at': '2021-10-17T07:28:31Z',\n",
       "  'updated_at': '2025-05-30T06:38:38Z',\n",
       "  'stars': 100,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/PPO-BiHyb'},\n",
       " {'name': 'pygmtools',\n",
       "  'description': 'A Python Graph Matching Toolkit.',\n",
       "  'created_at': '2021-10-18T16:33:24Z',\n",
       "  'updated_at': '2025-09-05T03:36:44Z',\n",
       "  'stars': 339,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/pygmtools'},\n",
       " {'name': 'EDA-AI',\n",
       "  'description': 'Implementations of DeepPlace, PRNet, HubRouter, PreRoutGNN, FlexPlanner and DSBRouter.',\n",
       "  'created_at': '2021-10-24T03:47:55Z',\n",
       "  'updated_at': '2025-09-03T03:02:47Z',\n",
       "  'stars': 268,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/EDA-AI'},\n",
       " {'name': 'awesome-molecular-docking',\n",
       "  'description': 'We would like to maintain a list of resources which aim to solve molecular docking and other closely related tasks.',\n",
       "  'created_at': '2022-12-10T13:41:07Z',\n",
       "  'updated_at': '2025-06-29T05:40:34Z',\n",
       "  'stars': 102,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/awesome-molecular-docking'},\n",
       " {'name': 'awesome-ai4eda',\n",
       "  'description': 'Awesome Artificial Intelligence for Electronic Design Automation Papers.',\n",
       "  'created_at': '2023-02-13T10:53:46Z',\n",
       "  'updated_at': '2025-09-05T09:58:33Z',\n",
       "  'stars': 177,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/awesome-ai4eda'},\n",
       " {'name': 'Crossformer',\n",
       "  'description': 'Official implementation of our ICLR 2023 paper \"Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting\"',\n",
       "  'created_at': '2023-02-14T13:16:51Z',\n",
       "  'updated_at': '2025-08-28T23:09:16Z',\n",
       "  'stars': 601,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/Crossformer'},\n",
       " {'name': 'LinSATNet',\n",
       "  'description': 'Official implementation of our ICML 2023 paper \"LinSATNet: The Positive Linear Satisfiability Neural Networks\".',\n",
       "  'created_at': '2023-05-25T14:12:38Z',\n",
       "  'updated_at': '2025-09-03T01:46:56Z',\n",
       "  'stars': 73,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/LinSATNet'},\n",
       " {'name': 'Awesome-LLM4AD',\n",
       "  'description': 'A curated list of awesome LLM/VLM/VLA for Autonomous Driving(LLM4AD) resources (continually updated)',\n",
       "  'created_at': '2023-10-06T15:34:08Z',\n",
       "  'updated_at': '2025-09-06T02:56:37Z',\n",
       "  'stars': 1454,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/Awesome-LLM4AD'},\n",
       " {'name': 'T2TCO',\n",
       "  'description': '[NeurIPS 2023] T2T: From Distribution Learning in Training to Gradient Search in Testing for Combinatorial Optimization',\n",
       "  'created_at': '2023-11-01T11:02:33Z',\n",
       "  'updated_at': '2025-09-04T08:55:28Z',\n",
       "  'stars': 65,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/T2TCO'},\n",
       " {'name': 'Awesome-LLM4EDA',\n",
       "  'description': None,\n",
       "  'created_at': '2023-11-11T05:26:17Z',\n",
       "  'updated_at': '2025-09-04T17:29:16Z',\n",
       "  'stars': 227,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/Awesome-LLM4EDA'},\n",
       " {'name': 'ML4CO-Kit',\n",
       "  'description': 'A Python toolkit for Machine Learning (ML) practices for Combinatorial Optimization (CO).',\n",
       "  'created_at': '2024-04-11T06:16:38Z',\n",
       "  'updated_at': '2025-09-02T22:18:52Z',\n",
       "  'stars': 58,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/ML4CO-Kit'},\n",
       " {'name': 'Bench2Drive',\n",
       "  'description': '[NeurIPS 2024 Datasets and Benchmarks Track] Closed-Loop E2E-AD Benchmark Enhanced by World Model RL Expert',\n",
       "  'created_at': '2024-04-23T06:17:59Z',\n",
       "  'updated_at': '2025-09-04T15:22:52Z',\n",
       "  'stars': 1613,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/Bench2Drive'},\n",
       " {'name': 'Bench2DriveZoo',\n",
       "  'description': 'BEVFormer, UniAD, VAD in Closed-Loop CARLA Evaluation with World Model RL Expert Think2Drive',\n",
       "  'created_at': '2024-06-05T10:29:12Z',\n",
       "  'updated_at': '2025-09-05T02:26:45Z',\n",
       "  'stars': 293,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/Bench2DriveZoo'},\n",
       " {'name': 'DriveTransformer',\n",
       "  'description': None,\n",
       "  'created_at': '2025-03-06T13:28:34Z',\n",
       "  'updated_at': '2025-09-03T12:16:09Z',\n",
       "  'stars': 124,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/DriveTransformer'},\n",
       " {'name': 'DriveMoE',\n",
       "  'description': 'Drive-Pi0 and DriveMoE on End-to-end Autonomous Driving',\n",
       "  'created_at': '2025-05-19T04:00:11Z',\n",
       "  'updated_at': '2025-09-04T02:44:18Z',\n",
       "  'stars': 89,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/DriveMoE'},\n",
       " {'name': 'Bench2Drive-VL',\n",
       "  'description': 'Adapting VLMs to Bench2Drive.',\n",
       "  'created_at': '2025-05-19T07:43:43Z',\n",
       "  'updated_at': '2025-09-03T04:04:48Z',\n",
       "  'stars': 150,\n",
       "  'url': 'https://github.com/Thinklab-SJTU/Bench2Drive-VL'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43,
   "source": "",
   "id": "1aa5360adee5a629"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b3b2787ddc722f9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
