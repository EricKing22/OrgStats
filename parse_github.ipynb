{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:01:52.586630Z",
     "start_time": "2025-09-08T05:01:51.430640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:8890\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:8890\"\n",
    "# ucloud api key\n",
    "API_KEY = os.getenv(\"UCLOUD_API_KEY\")\n",
    "API_BASE = \"https://api.modelverse.cn/v1\"\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base=API_BASE,\n",
    "    model=\"deepseek-ai/DeepSeek-V3-0324\")\n",
    "output_parser = StrOutputParser()\n"
   ],
   "id": "20b3bc1e57d17b36",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:01:56.493059Z",
     "start_time": "2025-09-08T05:01:56.454767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"Github/\",\n",
    "    loader_cls=lambda path: TextLoader(path, encoding=\"utf-8\")\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "docs"
   ],
   "id": "9736683d6c479a49",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Github\\\\4paradigm_results.txt'}, page_content='**OpenMLDB**  \\n分类：2. 数据集  \\nstar数字：1662  \\n最后更新时间：2025-09-02  \\n项目描述：OpenMLDB is an open-source machine learning database that provides a feature platform computing consistent features for training and inference.  \\nurl: https://github.com/4paradigm/OpenMLDB  \\n\\n---\\n\\n**k8s-vgpu-scheduler**  \\n分类：3. 工具  \\nstar数字：572  \\n最后更新时间：2025-09-02  \\n项目描述：OpenAIOS vGPU device plugin for Kubernetes is originated from the OpenAIOS project to virtualize GPU device memory, in order to allow applications to access larger memory space than its physical capacity. It is designed for ease of use of extended device memory for AI workloads.  \\nurl: https://github.com/4paradigm/k8s-vgpu-scheduler  \\n\\n---\\n\\n**AutoX**  \\n分类：3. 工具  \\nstar数字：539  \\n最后更新时间：2025-08-07  \\n项目描述：AutoX is an efficient automl tool, which is mainly aimed at data mining tasks with tabular data.  \\nurl: https://github.com/4paradigm/AutoX  \\n\\n---\\n\\n**openaios-platform**  \\n分类：4. 其他  \\nstar数字：98  \\n最后更新时间：2025-07-18  \\n项目描述：OpenAIOS is an incubating open-source distributed OS kernel based on Kubernetes for AI workloads.  OpenAIOS-Platform is an AI development platform built upon OpenAIOS for enterprises to develop and deploy AI applications for production.  \\nurl: https://github.com/4paradigm/openaios-platform  \\n\\n---\\n\\n**pafka**  \\n分类：4. 其他  \\nstar数字：67  \\n最后更新时间：2024-09-23  \\n项目描述：Pafka is originated from the OpenAIOS project to leverage an optimized tiered storage access strategy to improve overall performance for streaming/messaging system.  \\nurl: https://github.com/4paradigm/pafka  \\n\\n'),\n",
       " Document(metadata={'source': 'Github\\\\AgibotTech_results.txt'}, page_content='**agibot_x1_infer**  \\n分类：1. 模型  \\nstar数字：1717  \\n最后更新时间：2025-09-06  \\n项目描述：The inference module for AgiBot X1.  \\nurl: https://github.com/AgibotTech/agibot_x1_infer  \\n\\n**agibot_x1_train**  \\n分类：1. 模型  \\nstar数字：1563  \\n最后更新时间：2025-09-02  \\n项目描述：The reinforcement learning training code for AgiBot X1.  \\nurl: https://github.com/AgibotTech/agibot_x1_train  \\n\\n**agibot_x1_hardware**  \\n分类：4. 其他  \\nstar数字：978  \\n最后更新时间：2025-09-05  \\n项目描述：The hardware design for AgiBot X1.  \\nurl: https://github.com/AgibotTech/agibot_x1_hardware  \\n\\n**Genie-Envisioner**  \\n分类：4. 其他  \\nstar数字：240  \\n最后更新时间：2025-09-06  \\n项目描述：None  \\nurl: https://github.com/AgibotTech/Genie-Envisioner  \\n\\n**genie_sim**  \\n分类：3. 工具  \\nstar数字：273  \\n最后更新时间：2025-09-05  \\n项目描述：The Simulation Framework from AgiBot  \\nurl: https://github.com/AgibotTech/genie_sim  \\n\\n**EnerVerse-AC**  \\n分类：1. 模型  \\nstar数字：111  \\n最后更新时间：2025-09-06  \\n项目描述：Official Code for EnerVerse-AC: Envisioning EmbodiedEnvironments with Action Condition  \\nurl: https://github.com/AgibotTech/EnerVerse-AC  \\n\\n**EWMBench**  \\n分类：2. 数据集  \\nstar数字：82  \\n最后更新时间：2025-08-30  \\n项目描述：Official code for EWMBench: Evaluating Scene, Motion, and Semantic Quality in Embodied World Models  \\nurl: https://github.com/AgibotTech/EWMBench'),\n",
       " Document(metadata={'source': 'Github\\\\ECNU-CILAB_results.txt'}, page_content=''),\n",
       " Document(metadata={'source': 'Github\\\\FFTAI_results.txt'}, page_content=\"**teleoperation**  \\n分类：工具  \\nstar数字：122  \\n最后更新时间：2025-09-03T08:10:32Z  \\n项目描述：A.K.A. Fourier Advanced Robot Teleoperation System (F.A.R.T.S.) 💨  \\nurl: https://github.com/FFTAI/teleoperation  \\n\\n---\\n\\n**Wiki-GRx-Deploy**  \\n分类：工具  \\nstar数字：112  \\n最后更新时间：2025-08-15T10:35:39Z  \\n项目描述：The Wiki-GRx code repository offers a fundamental module library and example code for the GRx motion control system. This repository serves as a resource for developers and engineers looking to implement or understand the GRx's capabilities in motion.  \\nurl: https://github.com/FFTAI/Wiki-GRx-Deploy  \\n\\n---\\n\\n**fourier-lerobot**  \\n分类：其他（无描述）  \\nstar数字：67  \\n最后更新时间：2025-09-04T13:11:56Z  \\n项目描述：None  \\nurl: https://github.com/FFTAI/fourier-lerobot  \\n\\n---\\n\\n**Wiki-GRx-Gym**  \\n分类：其他（无描述）  \\nstar数字：55  \\n最后更新时间：2025-09-01T06:29:53Z  \\n项目描述：None  \\nurl: https://github.com/FFTAI/Wiki-GRx-Gym  \\n\\n---\\n\\n**Wiki-GRx-MJCF**  \\n分类：工具  \\nstar数字：53  \\n最后更新时间：2025-08-28T09:23:41Z  \\n项目描述：This repository provide a tool to convert robot urdf file to mjcf.  \\nurl: https://github.com/FFTAI/Wiki-GRx-MJCF  \\n\\n---\\n\\n**Wiki-GRx-Pipeline**  \\n分类：其他  \\nstar数字：50  \\n最后更新时间：2025-09-04T06:19:41Z  \\n项目描述：The development pipeline of Fourier Intelligence GRx Series Robot.  \\nurl: https://github.com/FFTAI/Wiki-GRx-Pipeline  \\n\\n--- \\n\\n### 分类说明：\\n- **工具**：涉及机器人控制、文件转换或远程操作等实际功能（如 `teleoperation`, `Wiki-GRx-Deploy`, `Wiki-GRx-MJCF`）。  \\n- **其他**：描述不明确或无描述的项目（如 `fourier-lerobot`, `Wiki-GRx-Gym`），或描述未明确匹配其他标签（如 `Wiki-GRx-Pipeline`）。  \\n\\n所有项目均满足 `updated_at` 在 2023 年之后的要求。\"),\n",
       " Document(metadata={'source': 'Github\\\\fudan-generative-vision_results.txt'}, page_content='**hallo**  \\n分类：模型（音频驱动的肖像图像动画生成模型）  \\nstar数字：8571  \\n最后更新时间：2025-09-05  \\n项目描述：Hallo是一个通过分层音频驱动实现肖像图像动画合成的生成模型，具有高保真和可控性。  \\nURL: https://github.com/fudan-generative-vision/hallo  \\n\\n---\\n\\n**champ**  \\n分类：模型（基于3D参数化引导的人类图像动画生成模型）  \\nstar数字：4232  \\n最后更新时间：2025-09-05  \\n项目描述：Champ是一个可控且一致的人类图像动画生成框架，结合3D参数化指导，适用于动态场景生成。  \\nURL: https://github.com/fudan-generative-vision/champ  \\n\\n---\\n\\n**hallo2**  \\n分类：模型（长时长高分辨率音频驱动肖像动画生成模型）  \\nstar数字：3600  \\n最后更新时间：2025-09-02  \\n项目描述：Hallo2是Hallo的升级版，专注于长时长和高分辨率的音频驱动肖像动画生成，效果更稳定。  \\nURL: https://github.com/fudan-generative-vision/hallo2  \\n\\n---\\n\\n**hallo3**  \\n分类：模型（基于视频扩散Transformer的高动态肖像动画生成模型）  \\nstar数字：1302  \\n最后更新时间：2025-09-05  \\n项目描述：Hallo3利用视频扩散Transformer实现高度动态和逼真的肖像图像动画，支持复杂运动合成。  \\nURL: https://github.com/fudan-generative-vision/hallo3  \\n\\n---\\n\\n**dynamicPDB**  \\n分类：数据集（动态蛋白质结构数据库）  \\nstar数字：762  \\n最后更新时间：2025-09-02  \\n项目描述：DynamicPDB是一个动态蛋白质数据银行，提供结构生物学领域的高质量时序蛋白质数据。  \\nURL: https://github.com/fudan-generative-vision/dynamicPDB  \\n\\n---\\n\\n**DicFace**  \\n分类：模型（视频人脸修复的变分编码学习模型）  \\nstar数字：435  \\n最后更新时间：2025-08-20  \\n项目描述：DicFace通过狄利克雷约束变分编码本学习，实现时序一致的视频人脸修复，适用于低质量视频增强。  \\nURL: https://github.com/fudan-generative-vision/DicFace  \\n\\n---\\n\\n**OpenHumanVid**  \\n分类：数据集（以人为中心的视频生成数据集）  \\nstar数字：274  \\n最后更新时间：2025-09-05  \\n项目描述：OpenHumanVid是一个大规模高质量数据集，用于提升以人为中心的视频生成任务的真实性和多样性。  \\nURL: https://github.com/fudan-generative-vision/OpenHumanVid  \\n\\n\\n\\n注：`TemporalCodeFormer`和`PPFlow`因`stars ≤ 50`被过滤，`diffusion-genAI-course`因`stars = 46`被过滤。'),\n",
       " Document(metadata={'source': 'Github\\\\FudanDISC_results.txt'}, page_content='**DISC-LawLLM**  \\n分类：1. 模型（中文法律大模型）  \\nstar数字：777  \\n最后更新时间：2025-09-05  \\n项目描述：[中文法律大模型] DISC-LawLLM: an intelligent legal system powered by large language models (LLMs) to provide a wide range of legal services.  \\nurl: https://github.com/FudanDISC/DISC-LawLLM  \\n\\n---\\n\\n**DISC-FinLLM**  \\n分类：1. 模型（中文金融大语言模型）  \\nstar数字：768  \\n最后更新时间：2025-09-03  \\n项目描述：DISC-FinLLM，中文金融大语言模型（LLM），旨在为用户提供金融场景下专业、智能、全面的金融咨询服务。  \\nurl: https://github.com/FudanDISC/DISC-FinLLM  \\n\\n---\\n\\n**DISC-MedLLM**  \\n分类：1. 模型（医疗大语言模型）  \\nstar数字：550  \\n最后更新时间：2025-08-14  \\n项目描述：Repository of DISC-MedLLM, it is a comprehensive solution that leverages Large Language Models (LLMs) to provide accurate and truthful medical response in end-to-end conversational healthcare services.  \\nurl: https://github.com/FudanDISC/DISC-MedLLM  \\n\\n---\\n\\n**SocialAgent**  \\n分类：4. 其他（社交智能体资源集合）  \\nstar数字：179  \\n最后更新时间：2025-09-05  \\n项目描述：A collection of resources that investigate social agents.  \\nurl: https://github.com/FudanDISC/SocialAgent  \\n\\n---\\n\\n**SocioVerse**  \\n分类：4. 其他（无描述，暂归类）  \\nstar数字：119  \\n最后更新时间：2025-09-05  \\n项目描述：None  \\nurl: https://github.com/FudanDISC/SocioVerse  \\n\\n\\n--- \\n\\n注：  \\n1. `DISCOpen-MedBox-DialoDiagnosis`的star数量为23，但因其描述明确提到工具属性，优先归类到**工具**而非数据集。  \\n2. `SocioVerse`因无描述暂归类为**其他**。  \\n3. 所有项目均满足`updated_at` ≥ 2023年的条件。'),\n",
       " Document(metadata={'source': 'Github\\\\IAAR-Shanghai_results.txt'}, page_content='**SurveyX**  \\n分类：4. 其他  \\nstar数字：898  \\n最后更新时间：2025-09-04T12:12:42Z  \\n项目描述：Academic Survey Paper Generation.  \\nurl: https://github.com/IAAR-Shanghai/SurveyX  \\n\\n---\\n\\n**Awesome-Attention-Heads**  \\n分类：3. 工具  \\nstar数字：361  \\n最后更新时间：2025-09-04T13:59:08Z  \\n项目描述：An awesome repository & A comprehensive survey on interpretability of LLM attention heads.  \\nurl: https://github.com/IAAR-Shanghai/Awesome-Attention-Heads  \\n\\n---\\n\\n**CRUD_RAG**  \\n分类：2. 数据集  \\nstar数字：328  \\n最后更新时间：2025-08-26T03:16:24Z  \\n项目描述：CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models.  \\nurl: https://github.com/IAAR-Shanghai/CRUD_RAG  \\n\\n---\\n\\n**Meta-Chunking**  \\n分类：3. 工具  \\nstar数字：246  \\n最后更新时间：2025-09-02T09:35:41Z  \\n项目描述：Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception.  \\nurl: https://github.com/IAAR-Shanghai/Meta-Chunking  \\n\\n---\\n\\n**CTGSurvey**  \\n分类：4. 其他  \\nstar数字：185  \\n最后更新时间：2025-08-12T13:36:54Z  \\n项目描述：Controllable Text Generation for Large Language Models: A Survey.  \\nurl: https://github.com/IAAR-Shanghai/CTGSurvey  \\n\\n---\\n\\n**xFinder**  \\n分类：3. 工具  \\nstar数字：177  \\n最后更新时间：2025-08-28T01:04:17Z  \\n项目描述：[ICLR 2025] xFinder: Large Language Models as Automated Evaluators for Reliable Evaluation.  \\nurl: https://github.com/IAAR-Shanghai/xFinder  \\n\\n---\\n\\n**UHGEval**  \\n分类：2. 数据集  \\nstar数字：174  \\n最后更新时间：2025-09-03T01:50:14Z  \\n项目描述：[ACL 2024] User-friendly evaluation framework: Eval Suite & Benchmarks: UHGEval, HaluEval, HalluQA, etc.  \\nurl: https://github.com/IAAR-Shanghai/UHGEval  \\n\\n---\\n\\n**QAEncoder**  \\n分类：1. 模型  \\nstar数字：175  \\n最后更新时间：2025-09-02T09:35:40Z  \\n项目描述：[ACL 2025 Oral] QAEncoder: Towards Aligned Representation Learning in Question Answering Systems.  \\nurl: https://github.com/IAAR-Shanghai/QAEncoder  \\n\\n---\\n\\n**ICSFSurvey**  \\n分类：4. 其他  \\nstar数字：169  \\n最后更新时间：2025-08-13T00:22:01Z  \\n项目描述：Explore concepts like Self-Correct, Self-Refine, Self-Improve, Self-Contradict, Self-Play, and Self-Knowledge, alongside o1-like reasoning elevation🍓 and hallucination alleviation🍄.  \\nurl: https://github.com/IAAR-Shanghai/ICSFSurvey  \\n\\n---\\n\\n**xVerify**  \\n分类：3. 工具  \\nstar数字：128  \\n最后更新时间：2025-08-21T03:05:33Z  \\n项目描述：xVerify: Efficient Answer Verifier for Reasoning Model Evaluations.  \\nurl: https://github.com/IAAR-Shanghai/xVerify  \\n\\n---\\n\\n**Grimoire**  \\n分类：1. 模型  \\nstar数字：117  \\n最后更新时间：2025-09-02T16:13:40Z  \\n项目描述：Grimoire is All You Need for Enhancing Large Language Models.  \\nurl: https://github.com/IAAR-Shanghai/Grimoire  \\n\\n---\\n\\n**PGRAG**  \\n分类：4. 其他  \\nstar数字：53  \\n最后更新时间：2025-08-06T14:36:06Z  \\n项目描述：PGRAG.  \\nurl: https://github.com/IAAR-Shanghai/PGRAG  \\n\\n'),\n",
       " Document(metadata={'source': 'Github\\\\infinigence_results.txt'}, page_content='**Infini-Megrez**\\n分类：其他\\nstar数字：326\\n最后更新时间：2025-09-06T05:01:48Z\\n项目描述：None\\nurl: https://github.com/infinigence/Infini-Megrez\\n\\n**Infini-Megrez-Omni**\\n分类：其他\\nstar数字：239\\n最后更新时间：2025-09-05T12:52:14Z\\n项目描述：None\\nurl: https://github.com/infinigence/Infini-Megrez-Omni\\n\\n**FlashOverlap**\\n分类：工具\\nstar数字：161\\n最后更新时间：2025-09-05T06:51:15Z\\n项目描述：A lightweight design for computation-communication overlap.\\nurl: https://github.com/infinigence/FlashOverlap\\n\\n**Semi-PD**\\n分类：工具\\nstar数字：107\\n最后更新时间：2025-09-05T07:40:17Z\\n项目描述：A prefill & decode disaggregated LLM serving framework with shared GPU memory and fine-grained compute isolation.\\nurl: https://github.com/infinigence/Semi-PD\\n\\n**LVEval**\\n分类：数据集\\nstar数字：70\\n最后更新时间：2025-08-27T08:50:57Z\\n项目描述：Repository of LV-Eval Benchmark\\nurl: https://github.com/infinigence/LVEval'),\n",
       " Document(metadata={'source': 'Github\\\\infly-ai_results.txt'}, page_content=''),\n",
       " Document(metadata={'source': 'Github\\\\loongOpen_results.txt'}, page_content='**OpenLoong-Dyn-Control**  \\n分类：3. 工具（机器人动态控制软件包）  \\nstar数字：215  \\n最后更新时间：2025-09-05  \\n项目描述：Whole-Body Dynamics Control Software Package for Humanoid Robots  \\nurl: https://github.com/loongOpen/OpenLoong-Dyn-Control  \\n\\n**Unity-RL-Playground**  \\n分类：3. 工具（强化学习开发工具包）  \\nstar数字：151  \\n最后更新时间：2025-09-04  \\n项目描述：Reinforcement learning and imitation learning toolkits for robotics developers and for everyone.  \\nurl: https://github.com/loongOpen/Unity-RL-Playground  \\n\\n**OpenLoong-Gymloong**  \\n分类：3. 工具（机器人训练平台）  \\nstar数字：70  \\n最后更新时间：2025-08-28  \\n项目描述：Training Platform for Humanoid Robots  \\nurl: https://github.com/loongOpen/OpenLoong-Gymloong  \\n\\n---  \\n分类依据：  \\n所有项目均为机器人开发相关的软件工具包，无模型或数据集描述，故统一归类为「工具」。按 `stars` 降序排列。'),\n",
       " Document(metadata={'source': 'Github\\\\MemTensor_results.txt'}, page_content='**MemOS**  \\n分类：工具（各种可用于辅助的AI工具）  \\nstar数字：2413  \\n最后更新时间：2025-09-06T01:25:18Z  \\n项目描述：MemOS (Preview) | Intelligence Begins with Memory  \\nurl：https://github.com/MemTensor/MemOS  \\n\\n'),\n",
       " Document(metadata={'source': 'Github\\\\minimax-ai_results.txt'}, page_content=\"**MiniMax-M1**  \\n分类：模型  \\nstar数字：2844  \\n最后更新时间：2025-09-05T02:13:22Z  \\n项目描述：MiniMax-M1, the world's first open-weight, large-scale hybrid-attention reasoning model.  \\nurl: https://github.com/MiniMax-AI/MiniMax-M1  \\n\\n---\\n\\n**MiniMax-01**  \\n分类：模型  \\nstar数字：3137  \\n最后更新时间：2025-09-04T01:46:20Z  \\n项目描述：The official repo of MiniMax-Text-01 and MiniMax-VL-01, large-language-model & vision-language-model based on Linear Attention.  \\nurl: https://github.com/MiniMax-AI/MiniMax-01  \\n\\n---\\n\\n**MiniMax-MCP**  \\n分类：工具  \\nstar数字：932  \\n最后更新时间：2025-09-05T03:57:47Z  \\n项目描述：Official MiniMax Model Context Protocol (MCP) server that enables interaction with powerful Text to Speech, image generation and video generation APIs.  \\nurl: https://github.com/MiniMax-AI/MiniMax-MCP  \\n\\n---\\n\\n**One-RL-to-See-Them-All**  \\n分类：其他  \\nstar数字：311  \\n最后更新时间：2025-08-25T17:28:07Z  \\n项目描述：The official repo of One RL to See Them All: Visual Triple Unified Reinforcement Learning.  \\nurl: https://github.com/MiniMax-AI/One-RL-to-See-Them-All  \\n\\n---\\n\\n**SynLogic**  \\n分类：其他  \\nstar数字：163  \\n最后更新时间：2025-08-25T17:28:13Z  \\n项目描述：The official repo of SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond.  \\nurl: https://github.com/MiniMax-AI/SynLogic  \\n\\n---\\n\\n**awesome-minimax-integrations**  \\n分类：工具  \\nstar数字：54  \\n最后更新时间：2025-07-04T00:59:42Z  \\n项目描述：Explore these applications integrating MiniMax's multimodal API to see how text, vision, and speech processing capabilities are incorporated into various software.  \\nurl: https://github.com/MiniMax-AI/awesome-minimax-integrations  \\n\\n---\\n\\n**MiniMax-AI.github.io**  \\n分类：其他  \\nstar数字：52  \\n最后更新时间：2025-09-01T09:21:11Z  \\n项目描述：The official GitHub Page for MiniMax.  \\nurl: https://github.com/MiniMax-AI/MiniMax-AI.github.io  \\n\\n---\\n\\n**MiniMax-MCP-JS**  \\n分类：工具  \\nstar数字：81  \\n最后更新时间：2025-09-01T15:32:47Z  \\n项目描述：Official MiniMax Model Context Protocol (MCP) JavaScript implementation that provides seamless integration with MiniMax's powerful AI capabilities including image generation, video generation, text-to-speech, and voice cloning APIs.  \\nurl: https://github.com/MiniMax-AI/MiniMax-MCP-JS  \\n\"),\n",
       " Document(metadata={'source': 'Github\\\\opengvlab_results.txt'}, page_content='### **模型**  \\n1. **InternVL**  \\n   分类：模型  \\n   star数字：9036  \\n   最后更新时间：2025-09-06  \\n   项目描述：[CVPR 2024 Oral] InternVL Family: A Pioneering Open-Source Alternative to GPT-4o. 接近GPT-4o表现的开源多模态对话模型  \\n   url: https://github.com/OpenGVLab/InternVL  \\n\\n2. **LLaMA-Adapter**  \\n   分类：模型  \\n   star数字：5895  \\n   最后更新时间：2025-09-04  \\n   项目描述：[ICLR 2024] Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters  \\n   url: https://github.com/OpenGVLab/LLaMA-Adapter  \\n\\n3. **DragGAN**  \\n   分类：模型  \\n   star数字：4981  \\n   最后更新时间：2025-09-03  \\n   项目描述：Unofficial Implementation of DragGAN - \"Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold\" （DragGAN 全功能实现，在线Demo，本地部署试用，代码、模型已全部开源，支持Windows, macOS, Linux）  \\n   url: https://github.com/OpenGVLab/DragGAN  \\n\\n4. **InternImage**  \\n   分类：模型  \\n   star数字：2727  \\n   最后更新时间：2025-09-05  \\n   项目描述：[CVPR 2023 Highlight] InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions  \\n   url: https://github.com/OpenGVLab/InternImage  \\n\\n5. **Ask-Anything**  \\n   分类：模型  \\n   star数字：3297  \\n   最后更新时间：2025-09-03  \\n   项目描述：[CVPR2024 Highlight][VideoChatGPT] ChatGPT with video understanding! And many more supported LMs such as miniGPT4, StableLM, and MOSS.  \\n   url: https://github.com/OpenGVLab/Ask-Anything  \\n\\n6. **InternGPT**  \\n   分类：模型  \\n   star数字：3217  \\n   最后更新时间：2025-09-02  \\n   项目描述：InternGPT (iGPT) is an open source demo platform where you can easily showcase your AI models. Now it supports DragGAN, ChatGPT, ImageBind, multimodal chat like GPT-4, SAM, interactive image editing, etc.  \\n   url: https://github.com/OpenGVLab/InternGPT  \\n\\n7. **InternVideo**  \\n   分类：模型  \\n   star数字：2036  \\n   最后更新时间：2025-09-05  \\n   项目描述：[ECCV2024] Video Foundation Models & Data for Multimodal Understanding  \\n   url: https://github.com/OpenGVLab/InternVideo  \\n\\n8. **VisionLLM**  \\n   分类：模型  \\n   star数字：1103  \\n   最后更新时间：2025-09-04  \\n   项目描述：VisionLLM Series  \\n   url: https://github.com/OpenGVLab/VisionLLM  \\n\\n9. **VideoMamba**  \\n   分类：模型  \\n   star数字：990  \\n   最后更新时间：2025-09-02  \\n   项目描述：[ECCV2024] VideoMamba: State Space Model for Efficient Video Understanding  \\n   url: https://github.com/OpenGVLab/VideoMamba  \\n\\n10. **OmniQuant**  \\n    分类：模型  \\n    star数字：845  \\n    最后更新时间：2025-09-06  \\n    项目描述：[ICLR2024 spotlight] OmniQuant is a simple and powerful quantization technique for LLMs.  \\n    url: https://github.com/OpenGVLab/OmniQuant  \\n\\n11. **SAM-Med2D**  \\n    分类：模型  \\n    star数字：1031  \\n    最后更新时间：2025-09-04  \\n    项目描述：Official implementation of SAM-Med2D  \\n    url: https://github.com/OpenGVLab/SAM-Med2D  \\n\\n12. **VideoMAEv2**  \\n    分类：模型  \\n    star数字：676  \\n    最后更新时间：2025-08-27  \\n    项目描述：[CVPR 2023] VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking  \\n    url: https://github.com/OpenGVLab/VideoMAEv2  \\n\\n13. **GITM**  \\n    分类：模型  \\n    star数字：633  \\n    最后更新时间：2025-09-03  \\n    项目描述：Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory  \\n    url: https://github.com/OpenGVLab/GITM  \\n\\n14. **UniFormerV2**  \\n    分类：模型  \\n    star数字：327  \\n    最后更新时间：2025-08-26  \\n    项目描述：[ICCV2023] UniFormerV2: Spatiotemporal Learning by Arming Image ViTs with Video UniFormer  \\n    url: https://github.com/OpenGVLab/UniFormerV2  \\n\\n15. **CaFo**  \\n    分类：模型  \\n    star数字：377  \\n    最后更新时间：2025-09-05  \\n    项目描述：[CVPR 2023] Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners  \\n    url: https://github.com/OpenGVLab/CaFo  \\n\\n16. **all-seeing**  \\n    分类：模型  \\n    star数字：495  \\n    最后更新时间：2025-08-23  \\n    项目描述：[ICLR 2024 & ECCV 2024] The All-Seeing Projects: Towards Panoptic Visual Recognition&Understanding and General Relation Comprehension of the Open World  \\n    url: https://github.com/OpenGVLab/all-seeing  \\n\\n17. **LAMM**  \\n    分类：模型  \\n    star数字：317  \\n    最后更新时间：2025-08-20  \\n    项目描述：[NeurIPS 2023 Datasets and Benchmarks Track] LAMM: Multi-Modal Large Language Models and Applications as AI Agents  \\n    url: https://github.com/OpenGVLab/LAMM  \\n\\n18. **unmasked_teacher**  \\n    分类：模型  \\n    star数字：337  \\n    最后更新时间：2025-08-29  \\n    项目描述：[ICCV2023 Oral] Unmasked Teacher: Towards Training-Efficient Video Foundation Models  \\n    url: https://github.com/OpenGVLab/unmasked_teacher  \\n\\n19. **Vision-RWKV**  \\n    分类：模型  \\n    star数字：493  \\n    最后更新时间：2025-09-06  \\n    项目描述：[ICLR 2025 Spotlight] Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures  \\n    url: https://github.com/OpenGVLab/Vision-RWKV  \\n\\n20. **M3I-Pretraining**  \\n    分类：模型  \\n    star数字：91  \\n    最后更新时间：2025-09-05  \\n    项目描述：[CVPR 2023] implementation of Towards All-in-one Pre-training via Maximizing Multi-modal Mutual Information.  \\n    url: https://github.com/OpenGVLab/M3I-Pretraining  \\n\\n21. **MM-Interleaved**  \\n    分类：模型  \\n    star数字：240  \\n    最后更新时间：2025-09-01  \\n    项目描述：MM-Interleaved: Interleaved Image-Text Generative Modeling via Multi-modal Feature Synchronizer  \\n    url: https://github.com/OpenGVLab/MM-Interleaved  \\n\\n22. **VideoChat-Flash**  \\n    分类：模型  \\n    star数字：463  \\n    最后更新时间：2025-09-06  \\n    项目描述：VideoChat-Flash: Hierarchical Compression for Long-Context Video Modeling  \\n    url: https://github.com/OpenGVLab/VideoChat-Flash  \\n\\n23. **Mono-InternVL**  \\n    分类：模型  \\n    star数字：81  \\n    最后更新时间：2025-09-05  \\n    项目描述：[CVPR 2025] Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large Language Models with Endogenous Visual Pre-training  \\n    url: https://github.com/OpenGVLab/Mono-InternVL  \\n\\n---\\n\\n### **数据集**  \\n1. **gv-benchmark**  \\n   分类：数据集  \\n   star数字：189  \\n   最后更新时间：2024-09-13  \\n   项目描述：General Vision Benchmark, GV-B, a project from OpenGVLab  \\n   url: https://github.com/OpenGVLab/gv-benchmark  \\n\\n2. **EgoExoLearn**  \\n   分类：数据集  \\n   star数字：69  \\n   最后更新时间：2025-09-02  \\n   项目描述：[CVPR 2024] Data and benchmark code for the EgoExoLearn dataset  \\n   url: https://github.com/OpenGVLab/EgoExoLearn  \\n\\n3. **OmniCorpus**  \\n   分类：数据集  \\n   star数字：391  \\n   最后更新时间：2025-09-05  \\n   项目描述：[ICLR 2025 Spotlight] OmniCorpus: A Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text  \\n   url: https://github.com/OpenGVLab/OmniCorpus  \\n\\n4. **MMT-Bench**  \\n   分类：数据集  \\n   star数字：113  \\n   最后更新时间：2025-07-30  \\n   项目描述：[ICML 2024] | MMT-Bench: A Comprehensive Multimodal Benchmark for Evaluating Large Vision-Language Models Towards Multitask AGI  \\n   url: https://github.com/OpenGVLab/MMT-Bench  \\n\\n5. **MM-NIAH**  \\n   分类：数据集  \\n   star数字：115  \\n   最后更新时间：2025-08-14  \\n   项目描述：[NeurIPS 2024] Needle In A Multimodal Haystack (MM-NIAH): A comprehensive benchmark designed to systematically evaluate the capability of existing MLLMs to comprehend long multimodal documents.  \\n   url: https://github.com/OpenGVLab/MM-NIAH  \\n\\n6. **GUI-Odyssey**  \\n   分类：数据集  \\n   star数字：129  \\n   最后更新时间：2025-09-04  \\n   项目描述：[ICCV 2025] GUIOdyssey is a comprehensive dataset for training and evaluating cross-app navigation agents.  \\n   url: https://github.com/OpenGVLab/GUI-Odyssey  \\n\\n7. **PhyGenBench**  \\n   分类：数据集  \\n   star数字：117  \\n   最后更新时间：2025-08-07  \\n   项目描述：[ICML2025] The code and data of Paper: Towards World Simulator: Crafting Physical Commonsense-Based Benchmark for Video Generation  \\n   url: https://github.com/OpenGVLab/PhyGenBench  \\n\\n---\\n\\n### **工具**  \\n1. **Multi-Modality-Arena**  \\n   分类：工具  \\n   star数字：535  \\n   最后更新时间：2025-08-24  \\n   项目描述：Chatbot Arena meets multi-modality! Multi-Modality Arena allows you to benchmark vision-language models side-by-side while providing images as inputs. Supports MiniGPT-4, LLaMA-Adapter V2, LLaVA, BLIP-2, and many more!  \\n   url: https://github.com/OpenGVLab/Multi-Modality-Arena  \\n\\n2. **Instruct2Act**  \\n   分类：工具  \\n   star数字：369  \\n   最后更新时间：2025-09-02  \\n   项目描述：Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model  \\n   url: https://github.com/OpenGVLab/Instruct2Act  \\n\\n3. **DiffRate**  \\n   分类：工具  \\n   star数字：100  \\n   最后更新时间：2025-09-05  \\n   项目描述：[ICCV 23]An approach to enhance the efficiency of Vision Transformer (ViT) by concurrently employing token pruning and token merging techniques, while incorporating a differentiable compression rate.  \\n   url: https://github.com/OpenGVLab/DiffRate  \\n\\n4. **ControlLLM**  \\n   分类：工具  \\n   star数字：193  \\n   最后更新时间：2025-07-14  \\n   项目描述：ControlLLM: Augment Language Models with Tools by Searching on Graphs  \\n   url: https://github.com/OpenGVLab/ControlLLM  \\n\\n5. **Awesome-DragGAN**  \\n   分类：工具  \\n   star数字：85  \\n   最后更新时间：2025-06-15  \\n   项目描述：Awesome-DragGAN: A curated list of papers, tutorials, repositories related to DragGAN  \\n   url: https://github.com/OpenGVLab/Awesome-DragGAN  \\n\\n6. **Awesome-LLM4Tool**  \\n   分类：工具  \\n   star数字：68  \\n   最后更新时间：2025-08-07  \\n   项目描述：A curated list of the papers, repositories, tutorials, and anythings related to the large language models for tools  \\n   url: https://github.com/OpenGVLab/Awesome-LLM4Tool  \\n\\n7. **ZeroGUI**  \\n   分类：工具  \\n   star数字：85  \\n   最后更新时间：2025-09-01  \\n   项目描述：ZeroGUI: Automating Online GUI Learning at Zero Human Cost  \\n   url: https://github.com/OpenGVLab/ZeroGUI  \\n\\n---\\n\\n### **其他**  \\n1. **HumanBench**  \\n   分类：其他  \\n   star数字：247  \\n   最后更新时间：2025-06-16  \\n   项目描述：This repo is official implementation of HumanBench (CVPR2023)  \\n   url: https://github.com/OpenGVLab/HumanBench  \\n\\n2. **UniHCP**  \\n   分类：其他  \\n   star数字：156  \\n   最后更新时间：2025-07-29  \\n   项目描述：Official PyTorch implementation of UniHCP  \\n   url: https://github.com/OpenGVLab/UniHCP  \\n\\n3. **LORIS**  \\n   分类：其他  \\n   star数字：61  \\n   最后更新时间：2025-08-28  \\n   项目描述：[ICML2023] Long-Term Rhythmic Video Soundtracker  \\n   url: https://github.com/OpenGVLab/LORIS  \\n\\n4. **MUTR**  \\n   分类：其他  \\n   star数字：82  \\n   最后更新时间：2025-08-07  \\n   项目描述：「AAAI 2024」 Referred by Multi-Modality: A Unified Temporal Transformers for Video Object Segmentation  \\n   url: https://github.com/OpenGVLab/MUTR  \\n\\n5. **DDPS**  \\n   分类：其他  \\n   star数字：72  \\n   最后更新时间：2025-08-18  \\n   项目描述：Official Implementation of \"Denoising Diffusion Semantic Segmentation with Mask Prior Modeling\"  \\n   url: https://github.com/OpenGVLab/DDPS  \\n\\n6. **DCNv4**  \\n   分类：其他  \\n   star数字：664  \\n   最后更新时间：2025-09-05  \\n   项目描述：[CVPR 2024] Deformable Convolution v4  \\n   url: https://github.com/OpenGVLab/DCNv4  \\n\\n7. **ChartAst**  \\n   分类：其他  \\n   star数字：124  \\n   最后更新时间：2025-08-31  \\n   项目描述：[ACL 2024] ChartAssistant is a chart-based vision-language model for universal chart comprehension and reasoning.  \\n   url: https://github.com/OpenGVLab/ChartAst  \\n\\n8. **Hulk**  \\n   分类：其他  \\n   star数字：137  \\n   最后更新时间：2025-08-22  \\n   项目描述：An official implementation of \"Hulk: A Universal Knowledge Translator for Human-Centric Tasks\"  \\n   url: https://github.com/OpenGVLab/Hulk  \\n\\n9. **PonderV2**  \\n   分类：其他  \\n   star数字：359  \\n   最后更新时间：2025-08-15  \\n   项目描述：[T-PAMI 2025] PonderV2: Pave the Way for 3D Foundation Model with A Universal Pre-training Paradigm  \\n   url: https://github.com/OpenGVLab/PonderV2  \\n\\n10. **LCL**  \\n    分类：其他  \\n    star数字：70  \\n    最后更新时间：2025-08-12  \\n    项目描述：[NeurIPS 2024] Vision Model Pre-training on Interleaved Image-Text Data via Latent Compression Learning  \\n    url: https://github.com/OpenGVLab/LCL  \\n\\n11. **EfficientQAT**  \\n    分类：其他  \\n    star数字：300  \\n    最后更新时间：2025-09-05  \\n    项目描述：[ACL 2025 Main] EfficientQAT: Efficient Quantization-Aware Training for Large Language Models  \\n    url: https://github.com/OpenGVLab/EfficientQAT  \\n\\n12. **Diffree**  \\n    分类：其他  \\n    star数字：239  \\n    最后更新时间：2025-08-04  \\n    项目描述：Diffree: Text-Guided Shape Free Object Inpainting with Diffusion Model  \\n    url: https://github.com/OpenGVLab/Diffree  \\n\\n13. **MMIU**  \\n    分类：其他  \\n    star数字：86  \\n    最后更新时间：2025-09-02  \\n    项目描述：[ICLR2025] MMIU: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models  \\n    url: https://github.com/OpenGVLab/MMIU  \\n\\n14. **vinci**  \\n    分类：其他  \\n    star数字：71  \\n    最后更新时间：2025-09-02  \\n    项目描述：Vinci: A Real-time Embodied Smart Assistant based on Egocentric Vision-Language Model  \\n    url: https://github.com/OpenGVLab/vinci  \\n\\n15. **V2PE**  \\n    分类：其他  \\n    star数字：56  \\n    最后更新时间：2025-09-06  \\n    项目描述：[ArXiv] V2PE: Improving Multimodal Long-Context Capability of Vision-Language Models with Variable Visual Position Encoding  \\n    url: https://github.com/OpenGVLab/V2PE  \\n\\n16. **TPO**  \\n    分类：其他  \\n    star数字：58  \\n    最后更新时间：2025-09-03  \\n    项目描述：Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment  \\n    url: https://github.com/OpenGVLab/TPO  \\n\\n17. **VideoChat-R1**  \\n    分类：其他  \\n    star数字：182  \\n    最后更新时间：2025-09-05  \\n    项目描述：VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning  \\n    url: https://github.com/OpenGVLab/VideoChat-R1  \\n\\n18. **VeBrain**  \\n    分类：其他  \\n    star数字：80  \\n    最后更新时间：2025-08-31  \\n    项目描述：Visual Embodied Brain: Let Multimodal Large Language Models See, Think, and Control in Spaces  \\n    url: https://github.com/OpenGVLab/VeBrain  \\n\\n--- \\n\\n注：`efficient-video-recognition`、`STM-Evaluation`、`DriveMLM` 因无描述或更新时间不符合要求被省略。'),\n",
       " Document(metadata={'source': 'Github\\\\OpenMOSS_results.txt'}, page_content='**MOSS**  \\n分类：模型  \\nstar数字：12060  \\n最后更新时间：2025-09-06  \\n项目描述：复旦大学开源的增强工具对话语言模型。  \\nurl: https://github.com/OpenMOSS/MOSS  \\n\\n---\\n\\n**MOSS-TTSD**  \\n分类：模型  \\nstar数字：941  \\n最后更新时间：2025-09-05  \\n项目描述：支持中英文表达性对话语音合成的模型，具备零样本多说话人克隆和长文本生成能力。  \\nurl: https://github.com/OpenMOSS/MOSS-TTSD  \\n\\n---\\n\\n**AnyGPT**  \\n分类：模型  \\nstar数字：861  \\n最后更新时间：2025-09-05  \\n项目描述：基于离散序列建模的统一多模态大语言模型。  \\nurl: https://github.com/OpenMOSS/AnyGPT  \\n\\n---\\n\\n**CoLLiE**  \\n分类：工具  \\nstar数字：416  \\n最后更新时间：2025-08-20  \\n项目描述：高效协作训练大语言模型的方法。  \\nurl: https://github.com/OpenMOSS/CoLLiE  \\n\\n---\\n\\n**SpeechGPT-2.0-preview**  \\n分类：模型  \\nstar数字：354  \\n最后更新时间：2025-09-02  \\n项目描述：达到GPT-4o水平的实时口语对话系统。  \\nurl: https://github.com/OpenMOSS/SpeechGPT-2.0-preview  \\n\\n---\\n\\n**VLABench**  \\n分类：数据集  \\nstar数字：283  \\n最后更新时间：2025-09-04  \\n项目描述：用于公平评估视觉语言代理（VLA）、具身智能体和多模态模型的大规模基准。  \\nurl: https://github.com/OpenMOSS/VLABench  \\n\\n---\\n\\n**Language-Model-SAEs**  \\n分类：工具  \\nstar数字：146  \\n最后更新时间：2025-08-30  \\n项目描述：专注于稀疏自编码器（SAE）在语言模型可解释性中的研究工具。  \\nurl: https://github.com/OpenMOSS/Language-Model-SAEs  \\n\\n---\\n\\n**HalluQA**  \\n分类：数据集  \\nstar数字：132  \\n最后更新时间：2025-08-07  \\n项目描述：用于评估中文大语言模型幻觉现象的数据集和脚本。  \\nurl: https://github.com/OpenMOSS/HalluQA  \\n\\n---\\n\\n**Say-I-Dont-Know**  \\n分类：其他  \\nstar数字：83  \\n最后更新时间：2025-08-14  \\n项目描述：研究AI助手能否识别自身知识盲区的项目（ICML 2024）。  \\nurl: https://github.com/OpenMOSS/Say-I-Dont-Know  \\n\\n---\\n\\n**GAOKAO-MM**  \\n分类：数据集  \\nstar数字：65  \\n最后更新时间：2025-08-07  \\n项目描述：中文多模态模型评估基准（ACL 2024 Findings）。  \\nurl: https://github.com/OpenMOSS/GAOKAO-MM  \\n\\n---\\n\\n**Thus-Spake-Long-Context-LLM**  \\n分类：其他  \\nstar数字：56  \\n最后更新时间：2025-08-20  \\n项目描述：从架构、基础设施、训练和评估四个角度分析长上下文大语言模型的综述。  \\nurl: https://github.com/OpenMOSS/Thus-Spake-Long-Context-LLM  \\n'),\n",
       " Document(metadata={'source': 'Github\\\\OpenSenseNova_results.txt'}, page_content='**piccolo-embedding**  \\n分类：模型（嵌入模型）  \\nstar数字：138  \\n最后更新时间：2025-08-28  \\n项目描述：code for piccolo embedding model from SenseTime  \\nurl: https://github.com/OpenSenseNova/piccolo-embedding  \\n'),\n",
       " Document(metadata={'source': 'Github\\\\stepfun-ai_results.txt'}, page_content='**Step-Audio**  \\n分类：其他  \\nstar数字：4502  \\n最后更新时间：2025-09-05T23:36:12Z  \\n项目描述：None  \\nurl: https://github.com/stepfun-ai/Step-Audio  \\n\\n**Step-Video-T2V**  \\n分类：其他  \\nstar数字：3105  \\n最后更新时间：2025-09-06T06:50:31Z  \\n项目描述：None  \\nurl: https://github.com/stepfun-ai/Step-Video-T2V  \\n\\n**Step1X-Edit**  \\n分类：模型  \\nstar数字：1615  \\n最后更新时间：2025-09-06T02:47:17Z  \\n项目描述：A SOTA open-source image editing model, which aims to provide comparable performance against the closed-source models like GPT-4o and Gemini 2 Flash.  \\nurl: https://github.com/stepfun-ai/Step1X-Edit  \\n\\n**Step-Audio2**  \\n分类：模型  \\nstar数字：889  \\n最后更新时间：2025-09-06T07:23:36Z  \\n项目描述：Step-Audio 2 is an end-to-end multi-modal large language model designed for industry-strength audio understanding and speech conversation.  \\nurl: https://github.com/stepfun-ai/Step-Audio2  \\n\\n**Step1X-3D**  \\n分类：模型  \\nstar数字：774  \\n最后更新时间：2025-09-06T01:12:25Z  \\n项目描述：Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured 3D Assets  \\nurl: https://github.com/stepfun-ai/Step1X-3D  \\n\\n**NextStep-1**  \\n分类：其他  \\nstar数字：526  \\n最后更新时间：2025-09-05T11:03:37Z  \\n项目描述：None  \\nurl: https://github.com/stepfun-ai/NextStep-1  \\n\\n**Step3**  \\n分类：其他  \\nstar数字：418  \\n最后更新时间：2025-09-06T06:49:25Z  \\n项目描述：None  \\nurl: https://github.com/stepfun-ai/Step3  \\n\\n**Step-Video-TI2V**  \\n分类：其他  \\nstar数字：352  \\n最后更新时间：2025-09-02T02:47:08Z  \\n项目描述：None  \\nurl: https://github.com/stepfun-ai/Step-Video-TI2V  \\n\\n**StepMesh**  \\n分类：其他  \\nstar数字：289  \\n最后更新时间：2025-09-05T03:55:45Z  \\n项目描述：None  \\nurl: https://github.com/stepfun-ai/StepMesh'),\n",
       " Document(metadata={'source': 'Github\\\\Thinklab-SJTU_results.txt'}, page_content='**Awesome-LLM4AD**  \\n分类：其他  \\nstar数字：1454  \\n最后更新时间：2025-09-06T02:56:37Z  \\n项目描述：A curated list of awesome LLM/VLM/VLA for Autonomous Driving(LLM4AD) resources (continually updated)  \\nurl: https://github.com/Thinklab-SJTU/Awesome-LLM4AD  \\n\\n**Bench2Drive**  \\n分类：数据集  \\nstar数字：1613  \\n最后更新时间：2025-09-04T15:22:52Z  \\n项目描述：[NeurIPS 2024 Datasets and Benchmarks Track] Closed-Loop E2E-AD Benchmark Enhanced by World Model RL Expert  \\nurl: https://github.com/Thinklab-SJTU/Bench2Drive  \\n\\n**awesome-ml4co**  \\n分类：其他  \\nstar数字：1950  \\n最后更新时间：2025-09-02T02:34:31Z  \\n项目描述：Awesome machine learning for combinatorial optzimization papers.  \\nurl: https://github.com/Thinklab-SJTU/awesome-ml4co  \\n\\n**ThinkMatch**  \\n分类：工具  \\nstar数字：872  \\n最后更新时间：2025-08-31T14:47:22Z  \\n项目描述：A research protocol for deep graph matching.  \\nurl: https://github.com/Thinklab-SJTU/ThinkMatch  \\n\\n**Crossformer**  \\n分类：模型  \\nstar数字：601  \\n最后更新时间：2025-08-28T23:09:16Z  \\n项目描述：Official implementation of our ICLR 2023 paper \"Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting\"  \\nurl: https://github.com/Thinklab-SJTU/Crossformer  \\n\\n**R3Det_Tensorflow**  \\n分类：工具  \\nstar数字：546  \\n最后更新时间：2025-03-06T05:52:31Z  \\n项目描述：Code for AAAI 2021 paper: R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object  \\nurl: https://github.com/Thinklab-SJTU/R3Det_Tensorflow  \\n\\n**pygmtools**  \\n分类：工具  \\nstar数字：339  \\n最后更新时间：2025-09-05T03:36:44Z  \\n项目描述：A Python Graph Matching Toolkit.  \\nurl: https://github.com/Thinklab-SJTU/pygmtools  \\n\\n**EDA-AI**  \\n分类：工具  \\nstar数字：268  \\n最后更新时间：2025-09-03T03:02:47Z  \\n项目描述：Implementations of DeepPlace, PRNet, HubRouter, PreRoutGNN, FlexPlanner and DSBRouter.  \\nurl: https://github.com/Thinklab-SJTU/EDA-AI  \\n\\n**Awesome-LLM4EDA**  \\n分类：其他  \\nstar数字：227  \\n最后更新时间：2025-09-04T17:29:16Z  \\n项目描述：None  \\nurl: https://github.com/Thinklab-SJTU/Awesome-LLM4EDA  \\n\\n**awesome-ai4eda**  \\n分类：其他  \\nstar数字：177  \\n最后更新时间：2025-09-05T09:58:33Z  \\n项目描述：Awesome Artificial Intelligence for Electronic Design Automation Papers.  \\nurl: https://github.com/Thinklab-SJTU/awesome-ai4eda  \\n\\n**Bench2Drive-VL**  \\n分类：其他  \\nstar数字：150  \\n最后更新时间：2025-09-03T04:04:48Z  \\n项目描述：Adapting VLMs to Bench2Drive.  \\nurl: https://github.com/Thinklab-SJTU/Bench2Drive-VL  \\n\\n**Bench2DriveZoo**  \\n分类：数据集  \\nstar数字：293  \\n最后更新时间：2025-09-05T02:26:45Z  \\n项目描述：BEVFormer, UniAD, VAD in Closed-Loop CARLA Evaluation with World Model RL Expert Think2Drive  \\nurl: https://github.com/Thinklab-SJTU/Bench2DriveZoo  \\n\\n**CSL_RetinaNet_Tensorflow**  \\n分类：工具  \\nstar数字：192  \\n最后更新时间：2025-06-13T20:11:34Z  \\n项目描述：Code for ECCV 2020 paper: Arbitrary-Oriented Object Detection with Circular Smooth Label  \\nurl: https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow  \\n\\n**awesome-molecular-docking**  \\n分类：其他  \\nstar数字：102  \\n最后更新时间：2025-06-29T05:40:34Z  \\n项目描述：We would like to maintain a list of resources which aim to solve molecular docking and other closely related tasks.  \\nurl: https://github.com/Thinklab-SJTU/awesome-molecular-docking  \\n\\n**PPO-BiHyb**  \\n分类：工具  \\nstar数字：100  \\n最后更新时间：2025-05-30T06:38:38Z  \\n项目描述：Implementation of our NeurIPS 2021 paper \"A Bi-Level Framework for Learning to Solve Combinatorial Optimization on Graphs\".  \\nurl: https://github.com/Thinklab-SJTU/PPO-BiHyb  \\n\\n**DriveTransformer**  \\n分类：模型  \\nstar数字：124  \\n最后更新时间：2025-09-03T12:16:09Z  \\n项目描述：None  \\nurl: https://github.com/Thinklab-SJTU/DriveTransformer  \\n\\n**LinSATNet**  \\n分类：模型  \\nstar数字：73  \\n最后更新时间：2025-09-03T01:46:56Z  \\n项目描述：Official implementation of our ICML 2023 paper \"LinSATNet: The Positive Linear Satisfiability Neural Networks\".  \\nurl: https://github.com/Thinklab-SJTU/LinSATNet  \\n\\n**T2TCO**  \\n分类：工具  \\nstar数字：65  \\n最后更新时间：2025-09-04T08:55:28Z  \\n项目描述：[NeurIPS 2023] T2T: From Distribution Learning in Training to Gradient Search in Testing for Combinatorial Optimization  \\nurl: https://github.com/Thinklab-SJTU/T2TCO  \\n\\n**S2TLD**  \\n分类：数据集  \\nstar数字：59  \\n最后更新时间：2025-05-13T02:06:16Z  \\n项目描述：Newly released traffic light dataset for small object detection.  \\nurl: https://github.com/Thinklab-SJTU/S2TLD  \\n\\n**ML4CO-Kit**  \\n分类：工具  \\nstar数字：58  \\n最后更新时间：2025-09-02T22:18:52Z  \\n项目描述：A Python toolkit for Machine Learning (ML) practices for Combinatorial Optimization (CO).  \\nurl: https://github.com/Thinklab-SJTU/ML4CO-Kit  \\n\\n**DriveMoE**  \\n分类：模型  \\nstar数字：89  \\n最后更新时间：2025-09-04T02:44:18Z  \\n项目描述：Drive-Pi0 and DriveMoE on End-to-end Autonomous Driving  \\nurl: https://github.com/Thinklab-SJTU/DriveMoE'),\n",
       " Document(metadata={'source': 'Github\\\\TigerResearch_results.txt'}, page_content='**TigerBot**  \\n分类：1. 模型  \\nstar数字：2258  \\n最后更新时间：2025-08-18  \\n项目描述：TigerBot: A multi-language multi-task LLM  \\nurl: https://github.com/TigerResearch/TigerBot  \\n\\n'),\n",
       " Document(metadata={'source': 'Github\\\\USTCAGI_results.txt'}, page_content=''),\n",
       " Document(metadata={'source': 'Github\\\\VISION-SJTU_results.txt'}, page_content=\"**PillarNet-LTS**  \\n分类：1. 模型（3D物体检测模型）  \\nstar数字：223  \\n最后更新时间：2025-09-06  \\n项目描述：[ECCV 2022] PillarNet: Real-Time and High-Performance Pillar-based 3D Object Detection  \\nurl: https://github.com/VISION-SJTU/PillarNet-LTS  \\n\\n**RECCE**  \\n分类：1. 模型（人脸伪造检测模型）  \\nstar数字：147  \\n最后更新时间：2025-09-06  \\n项目描述：[CVPR2022] End-to-End Reconstruction-Classification Learning for Face Forgery Detection  \\nurl: https://github.com/VISION-SJTU/RECCE  \\n\\n**Lightning-NeRF**  \\n分类：1. 模型（神经辐射场模型）  \\nstar数字：117  \\n最后更新时间：2025-07-06  \\n项目描述：[ICRA 2024] Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous Driving  \\nurl: https://github.com/VISION-SJTU/Lightning-NeRF  \\n\\n**PointAugmenting**  \\n分类：1. 模型（3D物体检测模型）  \\nstar数字：114  \\n最后更新时间：2025-08-27  \\n项目描述：[CVPR2021] PointAugmenting: Cross-Modal Augmentation for 3D Object Detection  \\nurl: https://github.com/VISION-SJTU/PointAugmenting  \\n\\n**3dSwap**  \\n分类：1. 模型（3D人脸交换模型）  \\nstar数字：86  \\n最后更新时间：2025-07-11  \\n项目描述：[CVPR 2023] 3D-Aware Face Swapping  \\nurl: https://github.com/VISION-SJTU/3dSwap  \\n\\n**USOT**  \\n分类：1. 模型（视觉目标跟踪模型）  \\nstar数字：64  \\n最后更新时间：2025-08-20  \\n项目描述：[ICCV2021] Learning to Track Objects from Unlabeled Videos  \\nurl: https://github.com/VISION-SJTU/USOT  \\n\\n**SparseOcc**  \\n分类：1. 模型（语义占据预测模型）  \\nstar数字：64  \\n最后更新时间：2025-08-30  \\n项目描述：Official implementation for 'SparseOcc: Rethinking Sparse Latent Representation for Vision-Based Semantic Occupancy Prediction' (CVPR 2024)  \\nurl: https://github.com/VISION-SJTU/SparseOcc  \\n\\n**IoUattack**  \\n分类：3. 工具（对抗攻击工具）  \\nstar数字：53  \\n最后更新时间：2025-07-08  \\n项目描述：[CVPR2021] IoU Attack: Towards Temporally Coherent Black-Box Adversarial Attack for Visual Object Tracking  \\nurl: https://github.com/VISION-SJTU/IoUattack  \\n\\n注：所有项目的updated_at都在2023年之后，因此没有项目被省略。\")]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:02:02.330884Z",
     "start_time": "2025-09-08T05:02:02.285513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "csvparser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instruction = \"您的响应应该是csv格式的逗号分隔值的列表，必须是：`分类，url, 项目名称, star数量`。你的回答必须只包含每列的标题以及csv文件中的内容，没有任何其他信息，例如\\'\\'\\' 和 csv。\""
   ],
   "id": "e5ccd7ead8bc5045",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:02:04.901863Z",
     "start_time": "2025-09-08T05:02:04.885840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=\"\"\"\n",
    "请查看以下内容并回答问题：\n",
    "\n",
    "{context}\n",
    "\n",
    "请分类每一个项目，相同类别的写在一起，不同类别直接空开一行。\n",
    "\n",
    "{format_instruction}\n",
    "\"\"\")"
   ],
   "id": "b84435dc0303bb88",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:02:12.809253Z",
     "start_time": "2025-09-08T05:02:06.739049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt | model | csvparser\n",
    "result = chain.invoke({\"context\":docs[0],\"format_instruction\":format_instruction})\n",
    "print(result)"
   ],
   "id": "2a8ab4456d391170",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['分类', 'url', '项目名称', 'star数量', '2. 数据集', 'https://github.com/4paradigm/OpenMLDB', 'OpenMLDB', '1662', '3. 工具', 'https://github.com/4paradigm/k8s-vgpu-scheduler', 'k8s-vgpu-scheduler', '572', '3. 工具', 'https://github.com/4paradigm/AutoX', 'AutoX', '539', '4. 其他', 'https://github.com/4paradigm/openaios-platform', 'openaios-platform', '98', '4. 其他', 'https://github.com/4paradigm/pafka', 'pafka', '67']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:05:15.758589Z",
     "start_time": "2025-09-08T05:02:57.984371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "for doc in docs:\n",
    "    chain = prompt | model | csvparser\n",
    "    result = chain.invoke({\"context\":doc,\"format_instruction\":format_instruction})\n",
    "    print(result)\n",
    "\n",
    "\n",
    "    HEADERS = [\"分类\", \"url\", \"项目名称\", \"star数量\"]\n",
    "\n",
    "    def chunk(lst, n):\n",
    "        for i in range(0, len(lst), n):\n",
    "            yield lst[i:i+n]\n",
    "\n",
    "    with open('github_csv.csv', 'a', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # writer.writerow(HEADERS)\n",
    "        for row in chunk(result[len(HEADERS):], len(HEADERS)):\n",
    "            if len(row) < len(HEADERS):  # 末尾不满一行时补空\n",
    "                row += [''] * (len(HEADERS) - len(row))\n",
    "            writer.writerow(row)\n",
    "        writer.writerow(\"\")"
   ],
   "id": "7ac768faa5bc2627",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['分类', 'url', '项目名称', 'star数量', '2. 数据集', 'https://github.com/4paradigm/OpenMLDB', 'OpenMLDB', '1662', '3. 工具', 'https://github.com/4paradigm/k8s-vgpu-scheduler', 'k8s-vgpu-scheduler', '572', '3. 工具', 'https://github.com/4paradigm/AutoX', 'AutoX', '539', '4. 其他', 'https://github.com/4paradigm/openaios-platform', 'openaios-platform', '98', '4. 其他', 'https://github.com/4paradigm/pafka', 'pafka', '67']\n",
      "['分类', 'url', '项目名称', 'star数量', '1. 模型', 'https://github.com/AgibotTech/agibot_x1_infer', 'agibot_x1_infer', '1717', '1. 模型', 'https://github.com/AgibotTech/agibot_x1_train', 'agibot_x1_train', '1563', '1. 模型', 'https://github.com/AgibotTech/EnerVerse-AC', 'EnerVerse-AC', '111', '4. 其他', 'https://github.com/AgibotTech/agibot_x1_hardware', 'agibot_x1_hardware', '978', '4. 其他', 'https://github.com/AgibotTech/Genie-Envisioner', 'Genie-Envisioner', '240', '3. 工具', 'https://github.com/AgibotTech/genie_sim', 'genie_sim', '273', '2. 数据集', 'https://github.com/AgibotTech/EWMBench', 'EWMBench', '82']\n",
      "['分类', 'url', '项目名称', 'star数量']\n",
      "['分类', 'url', '项目名称', 'star数量', '工具', 'https://github.com/FFTAI/teleoperation', 'teleoperation', '122', '工具', 'https://github.com/FFTAI/Wiki-GRx-Deploy', 'Wiki-GRx-Deploy', '112', '工具', 'https://github.com/FFTAI/Wiki-GRx-MJCF', 'Wiki-GRx-MJCF', '53', '其他', 'https://github.com/FFTAI/fourier-lerobot', 'fourier-lerobot', '67', '其他', 'https://github.com/FFTAI/Wiki-GRx-Gym', 'Wiki-GRx-Gym', '55', '其他', 'https://github.com/FFTAI/Wiki-GRx-Pipeline', 'Wiki-GRx-Pipeline', '50']\n",
      "['分类', 'url', '项目名称', 'star数量', '模型', 'https://github.com/fudan-generative-vision/hallo', 'hallo', '8571', '模型', 'https://github.com/fudan-generative-vision/champ', 'champ', '4232', '模型', 'https://github.com/fudan-generative-vision/hallo2', 'hallo2', '3600', '模型', 'https://github.com/fudan-generative-vision/hallo3', 'hallo3', '1302', '模型', 'https://github.com/fudan-generative-vision/DicFace', 'DicFace', '435', '数据集', 'https://github.com/fudan-generative-vision/dynamicPDB', 'dynamicPDB', '762', '数据集', 'https://github.com/fudan-generative-vision/OpenHumanVid', 'OpenHumanVid', '274']\n",
      "['分类', 'url', '项目名称', 'star数量', '1. 模型（中文法律大模型）', 'https://github.com/FudanDISC/DISC-LawLLM', 'DISC-LawLLM', '777', '1. 模型（中文金融大语言模型）', 'https://github.com/FudanDISC/DISC-FinLLM', 'DISC-FinLLM', '768', '1. 模型（医疗大语言模型）', 'https://github.com/FudanDISC/DISC-MedLLM', 'DISC-MedLLM', '550', '4. 其他（社交智能体资源集合）', 'https://github.com/FudanDISC/SocialAgent', 'SocialAgent', '179', '4. 其他（无描述，暂归类）', 'https://github.com/FudanDISC/SocioVerse', 'SocioVerse', '119']\n",
      "['分类', 'url', '项目名称', 'star数量  ', '4. 其他', 'https://github.com/IAAR-Shanghai/SurveyX', 'SurveyX', '898  ', '4. 其他', 'https://github.com/IAAR-Shanghai/CTGSurvey', 'CTGSurvey', '185  ', '4. 其他', 'https://github.com/IAAR-Shanghai/ICSFSurvey', 'ICSFSurvey', '169  ', '4. 其他', 'https://github.com/IAAR-Shanghai/PGRAG', 'PGRAG', '53  ', '3. 工具', 'https://github.com/IAAR-Shanghai/Awesome-Attention-Heads', 'Awesome-Attention-Heads', '361  ', '3. 工具', 'https://github.com/IAAR-Shanghai/Meta-Chunking', 'Meta-Chunking', '246  ', '3. 工具', 'https://github.com/IAAR-Shanghai/xFinder', 'xFinder', '177  ', '3. 工具', 'https://github.com/IAAR-Shanghai/xVerify', 'xVerify', '128  ', '2. 数据集', 'https://github.com/IAAR-Shanghai/CRUD_RAG', 'CRUD_RAG', '328  ', '2. 数据集', 'https://github.com/IAAR-Shanghai/UHGEval', 'UHGEval', '174  ', '1. 模型', 'https://github.com/IAAR-Shanghai/QAEncoder', 'QAEncoder', '175  ', '1. 模型', 'https://github.com/IAAR-Shanghai/Grimoire', 'Grimoire', '117']\n",
      "['分类', 'url', '项目名称', 'star数量', '其他', 'https://github.com/infinigence/Infini-Megrez', 'Infini-Megrez', '326', '其他', 'https://github.com/infinigence/Infini-Megrez-Omni', 'Infini-Megrez-Omni', '239', '工具', 'https://github.com/infinigence/FlashOverlap', 'FlashOverlap', '161', '工具', 'https://github.com/infinigence/Semi-PD', 'Semi-PD', '107', '数据集', 'https://github.com/infinigence/LVEval', 'LVEval', '70']\n",
      "['分类', 'url', '项目名称', 'star数量']\n",
      "['分类', 'url', '项目名称', 'star数量  ', '3. 工具（机器人动态控制软件包）', 'https://github.com/loongOpen/OpenLoong-Dyn-Control', 'OpenLoong-Dyn-Control', '215  ', '3. 工具（强化学习开发工具包）', 'https://github.com/loongOpen/Unity-RL-Playground', 'Unity-RL-Playground', '151  ', '3. 工具（机器人训练平台）', 'https://github.com/loongOpen/OpenLoong-Gymloong', 'OpenLoong-Gymloong', '70']\n",
      "['分类', 'url', '项目名称', 'star数量  ', '工具', 'https://github.com/MemTensor/MemOS', 'MemOS', '2413']\n",
      "['分类', 'url', '项目名称', 'star数量', '模型', 'https://github.com/MiniMax-AI/MiniMax-M1', 'MiniMax-M1', '2844', '模型', 'https://github.com/MiniMax-AI/MiniMax-01', 'MiniMax-01', '3137', '工具', 'https://github.com/MiniMax-AI/MiniMax-MCP', 'MiniMax-MCP', '932', '工具', 'https://github.com/MiniMax-AI/awesome-minimax-integrations', 'awesome-minimax-integrations', '54', '工具', 'https://github.com/MiniMax-AI/MiniMax-MCP-JS', 'MiniMax-MCP-JS', '81', '其他', 'https://github.com/MiniMax-AI/One-RL-to-See-Them-All', 'One-RL-to-See-Them-All', '311', '其他', 'https://github.com/MiniMax-AI/SynLogic', 'SynLogic', '163', '其他', 'https://github.com/MiniMax-AI/MiniMax-AI.github.io', 'MiniMax-AI.github.io', '52']\n",
      "['分类', 'url', '项目名称', 'star数量', '模型', 'https://github.com/OpenGVLab/InternVL', 'InternVL', '9036', '模型', 'https://github.com/OpenGVLab/LLaMA-Adapter', 'LLaMA-Adapter', '5895', '模型', 'https://github.com/OpenGVLab/DragGAN', 'DragGAN', '4981', '模型', 'https://github.com/OpenGVLab/InternImage', 'InternImage', '2727', '模型', 'https://github.com/OpenGVLab/Ask-Anything', 'Ask-Anything', '3297', '模型', 'https://github.com/OpenGVLab/InternGPT', 'InternGPT', '3217', '模型', 'https://github.com/OpenGVLab/InternVideo', 'InternVideo', '2036', '模型', 'https://github.com/OpenGVLab/VisionLLM', 'VisionLLM', '1103', '模型', 'https://github.com/OpenGVLab/VideoMamba', 'VideoMamba', '990', '模型', 'https://github.com/OpenGVLab/OmniQuant', 'OmniQuant', '845', '模型', 'https://github.com/OpenGVLab/SAM-Med2D', 'SAM-Med2D', '1031', '模型', 'https://github.com/OpenGVLab/VideoMAEv2', 'VideoMAEv2', '676', '模型', 'https://github.com/OpenGVLab/GITM', 'GITM', '633', '模型', 'https://github.com/OpenGVLab/UniFormerV2', 'UniFormerV2', '327', '模型', 'https://github.com/OpenGVLab/CaFo', 'CaFo', '377', '模型', 'https://github.com/OpenGVLab/all-seeing', 'all-seeing', '495', '模型', 'https://github.com/OpenGVLab/LAMM', 'LAMM', '317', '模型', 'https://github.com/OpenGVLab/unmasked_teacher', 'unmasked_teacher', '337', '模型', 'https://github.com/OpenGVLab/Vision-RWKV', 'Vision-RWKV', '493', '模型', 'https://github.com/OpenGVLab/M3I-Pretraining', 'M3I-Pretraining', '91', '模型', 'https://github.com/OpenGVLab/MM-Interleaved', 'MM-Interleaved', '240', '模型', 'https://github.com/OpenGVLab/VideoChat-Flash', 'VideoChat-Flash', '463', '模型', 'https://github.com/OpenGVLab/Mono-InternVL', 'Mono-InternVL', '81', '数据集', 'https://github.com/OpenGVLab/gv-benchmark', 'gv-benchmark', '189', '数据集', 'https://github.com/OpenGVLab/EgoExoLearn', 'EgoExoLearn', '69', '数据集', 'https://github.com/OpenGVLab/OmniCorpus', 'OmniCorpus', '391', '数据集', 'https://github.com/OpenGVLab/MMT-Bench', 'MMT-Bench', '113', '数据集', 'https://github.com/OpenGVLab/MM-NIAH', 'MM-NIAH', '115', '数据集', 'https://github.com/OpenGVLab/GUI-Odyssey', 'GUI-Odyssey', '129', '数据集', 'https://github.com/OpenGVLab/PhyGenBench', 'PhyGenBench', '117', '工具', 'https://github.com/OpenGVLab/Multi-Modality-Arena', 'Multi-Modality-Arena', '535', '工具', 'https://github.com/OpenGVLab/Instruct2Act', 'Instruct2Act', '369', '工具', 'https://github.com/OpenGVLab/DiffRate', 'DiffRate', '100', '工具', 'https://github.com/OpenGVLab/ControlLLM', 'ControlLLM', '193', '工具', 'https://github.com/OpenGVLab/Awesome-DragGAN', 'Awesome-DragGAN', '85', '工具', 'https://github.com/OpenGVLab/Awesome-LLM4Tool', 'Awesome-LLM4Tool', '68', '工具', 'https://github.com/OpenGVLab/ZeroGUI', 'ZeroGUI', '85', '其他', 'https://github.com/OpenGVLab/HumanBench', 'HumanBench', '247', '其他', 'https://github.com/OpenGVLab/UniHCP', 'UniHCP', '156', '其他', 'https://github.com/OpenGVLab/LORIS', 'LORIS', '61', '其他', 'https://github.com/OpenGVLab/MUTR', 'MUTR', '82', '其他', 'https://github.com/OpenGVLab/DDPS', 'DDPS', '72', '其他', 'https://github.com/OpenGVLab/DCNv4', 'DCNv4', '664', '其他', 'https://github.com/OpenGVLab/ChartAst', 'ChartAst', '124', '其他', 'https://github.com/OpenGVLab/Hulk', 'Hulk', '137', '其他', 'https://github.com/OpenGVLab/PonderV2', 'PonderV2', '359', '其他', 'https://github.com/OpenGVLab/LCL', 'LCL', '70', '其他', 'https://github.com/OpenGVLab/EfficientQAT', 'EfficientQAT', '300', '其他', 'https://github.com/OpenGVLab/Diffree', 'Diffree', '239', '其他', 'https://github.com/OpenGVLab/MMIU', 'MMIU', '86', '其他', 'https://github.com/OpenGVLab/vinci', 'vinci', '71', '其他', 'https://github.com/OpenGVLab/V2PE', 'V2PE', '56', '其他', 'https://github.com/OpenGVLab/TPO', 'TPO', '58', '其他', 'https://github.com/OpenGVLab/VideoChat-R1', 'VideoChat-R1', '182', '其他', 'https://github.com/OpenGVLab/VeBrain', 'VeBrain', '80']\n",
      "['分类', 'url', '项目名称', 'star数量', '模型', 'https://github.com/OpenMOSS/MOSS', 'MOSS', '12060', '模型', 'https://github.com/OpenMOSS/MOSS-TTSD', 'MOSS-TTSD', '941', '模型', 'https://github.com/OpenMOSS/AnyGPT', 'AnyGPT', '861', '模型', 'https://github.com/OpenMOSS/SpeechGPT-2.0-preview', 'SpeechGPT-2.0-preview', '354', '工具', 'https://github.com/OpenMOSS/CoLLiE', 'CoLLiE', '416', '工具', 'https://github.com/OpenMOSS/Language-Model-SAEs', 'Language-Model-SAEs', '146', '数据集', 'https://github.com/OpenMOSS/VLABench', 'VLABench', '283', '数据集', 'https://github.com/OpenMOSS/HalluQA', 'HalluQA', '132', '数据集', 'https://github.com/OpenMOSS/GAOKAO-MM', 'GAOKAO-MM', '65', '其他', 'https://github.com/OpenMOSS/Say-I-Dont-Know', 'Say-I-Dont-Know', '83', '其他', 'https://github.com/OpenMOSS/Thus-Spake-Long-Context-LLM', 'Thus-Spake-Long-Context-LLM', '56']\n",
      "['分类', 'url', '项目名称', 'star数量  ', '模型（嵌入模型）', 'https://github.com/OpenSenseNova/piccolo-embedding', 'piccolo-embedding', '138']\n",
      "['分类', 'url', '项目名称', 'star数量', '其他', 'https://github.com/stepfun-ai/Step-Audio', 'Step-Audio', '4502', '其他', 'https://github.com/stepfun-ai/Step-Video-T2V', 'Step-Video-T2V', '3105', '其他', 'https://github.com/stepfun-ai/NextStep-1', 'NextStep-1', '526', '其他', 'https://github.com/stepfun-ai/Step3', 'Step3', '418', '其他', 'https://github.com/stepfun-ai/Step-Video-TI2V', 'Step-Video-TI2V', '352', '其他', 'https://github.com/stepfun-ai/StepMesh', 'StepMesh', '289', '模型', 'https://github.com/stepfun-ai/Step1X-Edit', 'Step1X-Edit', '1615', '模型', 'https://github.com/stepfun-ai/Step-Audio2', 'Step-Audio2', '889', '模型', 'https://github.com/stepfun-ai/Step1X-3D', 'Step1X-3D', '774']\n",
      "['分类', 'url', '项目名称', 'star数量', '其他', 'https://github.com/Thinklab-SJTU/Awesome-LLM4AD', 'Awesome-LLM4AD', '1454', '其他', 'https://github.com/Thinklab-SJTU/awesome-ml4co', 'awesome-ml4co', '1950', '其他', 'https://github.com/Thinklab-SJTU/Awesome-LLM4EDA', 'Awesome-LLM4EDA', '227', '其他', 'https://github.com/Thinklab-SJTU/awesome-ai4eda', 'awesome-ai4eda', '177', '其他', 'https://github.com/Thinklab-SJTU/Bench2Drive-VL', 'Bench2Drive-VL', '150', '其他', 'https://github.com/Thinklab-SJTU/awesome-molecular-docking', 'awesome-molecular-docking', '102', '数据集', 'https://github.com/Thinklab-SJTU/Bench2Drive', 'Bench2Drive', '1613', '数据集', 'https://github.com/Thinklab-SJTU/Bench2DriveZoo', 'Bench2DriveZoo', '293', '数据集', 'https://github.com/Thinklab-SJTU/S2TLD', 'S2TLD', '59', '工具', 'https://github.com/Thinklab-SJTU/ThinkMatch', 'ThinkMatch', '872', '工具', 'https://github.com/Thinklab-SJTU/R3Det_Tensorflow', 'R3Det_Tensorflow', '546', '工具', 'https://github.com/Thinklab-SJTU/pygmtools', 'pygmtools', '339', '工具', 'https://github.com/Thinklab-SJTU/EDA-AI', 'EDA-AI', '268', '工具', 'https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow', 'CSL_RetinaNet_Tensorflow', '192', '工具', 'https://github.com/Thinklab-SJTU/PPO-BiHyb', 'PPO-BiHyb', '100', '工具', 'https://github.com/Thinklab-SJTU/T2TCO', 'T2TCO', '65', '工具', 'https://github.com/Thinklab-SJTU/ML4CO-Kit', 'ML4CO-Kit', '58', '模型', 'https://github.com/Thinklab-SJTU/Crossformer', 'Crossformer', '601', '模型', 'https://github.com/Thinklab-SJTU/DriveTransformer', 'DriveTransformer', '124', '模型', 'https://github.com/Thinklab-SJTU/LinSATNet', 'LinSATNet', '73', '模型', 'https://github.com/Thinklab-SJTU/DriveMoE', 'DriveMoE', '89']\n",
      "['分类', 'url', '项目名称', 'star数量', '1. 模型', 'https://github.com/TigerResearch/TigerBot', 'TigerBot', '2258']\n",
      "['分类', 'url', '项目名称', 'star数量']\n",
      "['分类', 'url', '项目名称', 'star数量', '1. 模型（3D物体检测模型）', 'https://github.com/VISION-SJTU/PillarNet-LTS', 'PillarNet-LTS', '223', '1. 模型（3D物体检测模型）', 'https://github.com/VISION-SJTU/PointAugmenting', 'PointAugmenting', '114', '1. 模型（人脸伪造检测模型）', 'https://github.com/VISION-SJTU/RECCE', 'RECCE', '147', '1. 模型（神经辐射场模型）', 'https://github.com/VISION-SJTU/Lightning-NeRF', 'Lightning-NeRF', '117', '1. 模型（3D人脸交换模型）', 'https://github.com/VISION-SJTU/3dSwap', '3dSwap', '86', '1. 模型（视觉目标跟踪模型）', 'https://github.com/VISION-SJTU/USOT', 'USOT', '64', '1. 模型（语义占据预测模型）', 'https://github.com/VISION-SJTU/SparseOcc', 'SparseOcc', '64', '3. 工具（对抗攻击工具）', 'https://github.com/VISION-SJTU/IoUattack', 'IoUattack', '53']\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
